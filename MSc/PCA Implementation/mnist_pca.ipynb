{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 7180 Play MNIST with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The MNIST [1] database is an image dataset of handwritten digits (0~9). Each image in MNIST is represented by a pixel matrix of 28\\*28, totally 784 elements. Since the images in MNIST are in gray scale, the value of each pixel ranges from 0 to 255, representing different gray degrees. \n",
    "\n",
    "For this assignment, we have two \".csv\" files, the training dataset \"mnist_train.csv\" and the testing dataset \"mnist_test.csv\". Each sample/row in the file represents an image sample. The first column indicates the handwritten digit of the image (label). Each of the rest columns denotes the value of each pixel axis (from 1 to 28 for both x-axis and y-axis) in an image. For example, the column \"1x28\" denotes the pixel value at $x=1$ (the first row) and $y=28$ (the 28th column). Now we want you to apply PCA to MNIST for data analytics as well as some advanced prediction tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load \"mnist_train.csv\" with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "train_data = pd.read_csv(\"./mnist_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Print the shape of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#28*28 = 784\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Take the pixel values of the first sample and reshape it to (28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>175</td>\n",
       "      <td>26</td>\n",
       "      <td>166</td>\n",
       "      <td>255</td>\n",
       "      <td>247</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>225</td>\n",
       "      <td>172</td>\n",
       "      <td>253</td>\n",
       "      <td>242</td>\n",
       "      <td>195</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>238</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>56</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>219</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>156</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>253</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>253</td>\n",
       "      <td>249</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>253</td>\n",
       "      <td>207</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>66</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>171</td>\n",
       "      <td>219</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>172</td>\n",
       "      <td>226</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>212</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3    4    5    6    7    8    9   ...   18   19   20   21  \\\n",
       "0    0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "1    0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "2    0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "3    0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "4    0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "5    0   0   0   0    0    0    0    0    0    0  ...  175   26  166  255   \n",
       "6    0   0   0   0    0    0    0    0   30   36  ...  225  172  253  242   \n",
       "7    0   0   0   0    0    0    0   49  238  253  ...   93   82   82   56   \n",
       "8    0   0   0   0    0    0    0   18  219  253  ...    0    0    0    0   \n",
       "9    0   0   0   0    0    0    0    0   80  156  ...    0    0    0    0   \n",
       "10   0   0   0   0    0    0    0    0    0   14  ...    0    0    0    0   \n",
       "11   0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "12   0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "13   0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "14   0   0   0   0    0    0    0    0    0    0  ...   25    0    0    0   \n",
       "15   0   0   0   0    0    0    0    0    0    0  ...  150   27    0    0   \n",
       "16   0   0   0   0    0    0    0    0    0    0  ...  253  187    0    0   \n",
       "17   0   0   0   0    0    0    0    0    0    0  ...  253  249   64    0   \n",
       "18   0   0   0   0    0    0    0    0    0    0  ...  253  207    2    0   \n",
       "19   0   0   0   0    0    0    0    0    0    0  ...  250  182    0    0   \n",
       "20   0   0   0   0    0    0    0    0    0    0  ...   78    0    0    0   \n",
       "21   0   0   0   0    0    0    0    0   23   66  ...    0    0    0    0   \n",
       "22   0   0   0   0    0    0   18  171  219  253  ...    0    0    0    0   \n",
       "23   0   0   0   0   55  172  226  253  253  253  ...    0    0    0    0   \n",
       "24   0   0   0   0  136  253  253  253  212  135  ...    0    0    0    0   \n",
       "25   0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "26   0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "27   0   0   0   0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "     22   23  24  25  26  27  \n",
       "0     0    0   0   0   0   0  \n",
       "1     0    0   0   0   0   0  \n",
       "2     0    0   0   0   0   0  \n",
       "3     0    0   0   0   0   0  \n",
       "4     0    0   0   0   0   0  \n",
       "5   247  127   0   0   0   0  \n",
       "6   195   64   0   0   0   0  \n",
       "7    39    0   0   0   0   0  \n",
       "8     0    0   0   0   0   0  \n",
       "9     0    0   0   0   0   0  \n",
       "10    0    0   0   0   0   0  \n",
       "11    0    0   0   0   0   0  \n",
       "12    0    0   0   0   0   0  \n",
       "13    0    0   0   0   0   0  \n",
       "14    0    0   0   0   0   0  \n",
       "15    0    0   0   0   0   0  \n",
       "16    0    0   0   0   0   0  \n",
       "17    0    0   0   0   0   0  \n",
       "18    0    0   0   0   0   0  \n",
       "19    0    0   0   0   0   0  \n",
       "20    0    0   0   0   0   0  \n",
       "21    0    0   0   0   0   0  \n",
       "22    0    0   0   0   0   0  \n",
       "23    0    0   0   0   0   0  \n",
       "24    0    0   0   0   0   0  \n",
       "25    0    0   0   0   0   0  \n",
       "26    0    0   0   0   0   0  \n",
       "27    0    0   0   0   0   0  \n",
       "\n",
       "[28 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstsample_label = train_data.iloc[0,0:1]\n",
    "firstsample_data = train_data.iloc[0,1:]\n",
    "data_reshape1 = firstsample_data.values.reshape(28,28)\n",
    "data_reshape1 = pd.DataFrame(data_reshape1)\n",
    "data_reshape1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Plot the above sample with plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e5862500d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data_reshape1, vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Split the dataset into X (the pixel values) and y (the digit label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y =  train_data.iloc[:,0:1]\n",
    "data_x = train_data.iloc[:,1:]\n",
    "\n",
    "data_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Standardize X by dividing 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>1x10</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  1x10  ...  28x19  28x20  \\\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0    0.0   \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0    0.0   \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0    0.0   \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0    0.0   \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0    0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...    ...    ...   \n",
       "59995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0    0.0   \n",
       "59996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0    0.0   \n",
       "59997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0    0.0   \n",
       "59998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0    0.0   \n",
       "59999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...    0.0    0.0   \n",
       "\n",
       "       28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "59995    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "59996    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "59997    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "59998    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "59999    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[60000 rows x 784 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_x = data_x/255.0\n",
    "std_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Apply PCA to X and obtain the eigenvalues as well as the eigenvectors (please implement it with numpy instead of other advanced libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.11687301e+00,  3.74139084e+00,  3.25270845e+00,  2.84162070e+00,\n",
       "        2.56711774e+00,  2.27366339e+00,  1.72515498e+00,  1.52056024e+00,\n",
       "        1.45630525e+00,  1.24275009e+00,  1.11208951e+00,  1.06664054e+00,\n",
       "        9.04680833e-01,  8.92181223e-01,  8.32353048e-01,  7.81900323e-01,\n",
       "        6.98386871e-01,  6.73255811e-01,  6.25995240e-01,  6.07763020e-01,\n",
       "        5.62145880e-01,  5.30798829e-01,  5.02780255e-01,  4.81147033e-01,\n",
       "        4.65783200e-01,  4.42538691e-01,  4.28439606e-01,  4.14618707e-01,\n",
       "        3.92667337e-01,  3.64261791e-01,  3.46985958e-01,  3.41741890e-01,\n",
       "        3.17734284e-01,  3.09280821e-01,  3.00549034e-01,  2.86632712e-01,\n",
       "        2.66680512e-01,  2.57227909e-01,  2.53838022e-01,  2.49006738e-01,\n",
       "        2.40823990e-01,  2.34543854e-01,  2.20658652e-01,  2.09962678e-01,\n",
       "        2.02981381e-01,  1.97776690e-01,  1.90872477e-01,  1.85379715e-01,\n",
       "        1.79298798e-01,  1.69711256e-01,  1.68204657e-01,  1.64929264e-01,\n",
       "        1.56059568e-01,  1.52353954e-01,  1.49810350e-01,  1.42107650e-01,\n",
       "        1.43117013e-01,  1.36282013e-01,  1.33802866e-01,  1.29062999e-01,\n",
       "        1.26809057e-01,  1.26153552e-01,  1.21484982e-01,  1.16804842e-01,\n",
       "        1.12686254e-01,  1.09261402e-01,  1.07056105e-01,  1.03755433e-01,\n",
       "        1.01683293e-01,  9.94581989e-02,  9.85853673e-02,  9.54776582e-02,\n",
       "        9.22166080e-02,  9.36212414e-02,  8.73975368e-02,  8.64145688e-02,\n",
       "        8.51323757e-02,  8.17865524e-02,  7.78302901e-02,  7.54908896e-02,\n",
       "        7.49204806e-02,  7.44243097e-02,  7.39082416e-02,  7.15682278e-02,\n",
       "        7.05721295e-02,  6.98071773e-02,  6.86266001e-02,  6.63677373e-02,\n",
       "        6.47622702e-02,  6.41065317e-02,  6.17074900e-02,  6.05681508e-02,\n",
       "        5.97090309e-02,  5.84654674e-02,  5.74722004e-02,  5.63762527e-02,\n",
       "        5.48385444e-02,  5.49382802e-02,  5.33882994e-02,  5.30039149e-02,\n",
       "        5.18832114e-02,  5.00730745e-02,  4.96330571e-02,  4.83057105e-02,\n",
       "        4.72884093e-02,  4.78672571e-02,  4.50897319e-02,  4.56285473e-02,\n",
       "        4.45860845e-02,  4.33668340e-02,  4.17370035e-02,  4.13691058e-02,\n",
       "        4.14393362e-02,  4.05373465e-02,  4.02834155e-02,  3.97072723e-02,\n",
       "        3.88475534e-02,  3.83386957e-02,  3.79442909e-02,  3.72675348e-02,\n",
       "        3.66668894e-02,  3.64948276e-02,  3.60277940e-02,  3.55404588e-02,\n",
       "        3.51616897e-02,  3.40222260e-02,  3.35122826e-02,  3.33041276e-02,\n",
       "        3.28447480e-02,  3.18247644e-02,  3.19144815e-02,  2.98096034e-02,\n",
       "        3.13445527e-02,  3.04139593e-02,  3.10190633e-02,  3.09248062e-02,\n",
       "        3.06517300e-02,  2.92504643e-02,  2.82173444e-02,  2.76860197e-02,\n",
       "        2.77298958e-02,  2.69037633e-02,  2.65195948e-02,  2.62950898e-02,\n",
       "        2.64197884e-02,  2.58921091e-02,  2.56004128e-02,  2.54585145e-02,\n",
       "        2.49928121e-02,  2.46942504e-02,  2.46018566e-02,  2.44293863e-02,\n",
       "        2.42166816e-02,  2.33422856e-02,  2.37466909e-02,  2.36637803e-02,\n",
       "        2.30240536e-02,  2.25376133e-02,  2.24074179e-02,  2.22509896e-02,\n",
       "        2.19083310e-02,  2.15984885e-02,  2.11338000e-02,  2.05891304e-02,\n",
       "        2.07782672e-02,  2.09787071e-02,  2.03444301e-02,  1.99778048e-02,\n",
       "        2.00240658e-02,  1.97162938e-02,  1.94777208e-02,  1.86988357e-02,\n",
       "        1.89747180e-02,  1.92529039e-02,  1.91823872e-02,  1.86068681e-02,\n",
       "        1.83111009e-02,  1.82409119e-02,  1.80031084e-02,  1.77735897e-02,\n",
       "        1.78026781e-02,  1.74115219e-02,  1.71837629e-02,  1.73128101e-02,\n",
       "        1.66706158e-02,  1.70275453e-02,  1.69392087e-02,  1.67298951e-02,\n",
       "        1.63947300e-02,  1.61323563e-02,  1.59004870e-02,  1.59904392e-02,\n",
       "        1.63206149e-02,  1.59448596e-02,  1.56441588e-02,  1.54735654e-02,\n",
       "        1.55935082e-02,  1.54314255e-02,  1.51720020e-02,  1.49923614e-02,\n",
       "        1.48669286e-02,  1.47142344e-02,  1.45383569e-02,  1.43664729e-02,\n",
       "        1.42062206e-02,  1.41151143e-02,  1.38080150e-02,  1.39786991e-02,\n",
       "        1.39368901e-02,  1.36797867e-02,  1.36326499e-02,  1.35464897e-02,\n",
       "        1.34312405e-02,  1.33297432e-02,  1.33022120e-02,  1.31584335e-02,\n",
       "        1.31032668e-02,  1.29745267e-02,  1.28627466e-02,  1.27524526e-02,\n",
       "        1.26776258e-02,  1.27052659e-02,  1.25629939e-02,  1.24883116e-02,\n",
       "        1.22628924e-02,  1.21337126e-02,  1.19995398e-02,  1.20260823e-02,\n",
       "        1.21959746e-02,  1.17460796e-02,  1.16979301e-02,  1.16230242e-02,\n",
       "        1.14872145e-02,  1.14234091e-02,  1.12936204e-02,  1.13447151e-02,\n",
       "        1.12229814e-02,  1.10920816e-02,  1.10595255e-02,  1.09122317e-02,\n",
       "        1.07703889e-02,  1.07942579e-02,  1.05971086e-02,  1.04922754e-02,\n",
       "        1.06144780e-02,  1.04202563e-02,  9.31607507e-03,  9.36178930e-03,\n",
       "        1.03251812e-02,  1.02144985e-02,  9.96929513e-03,  9.58982192e-03,\n",
       "        9.48361683e-03,  9.82770405e-03,  9.73415551e-03,  1.01113887e-02,\n",
       "        1.01686355e-02,  1.00992232e-02,  9.65654982e-03,  9.79898017e-03,\n",
       "        9.91313454e-03,  9.68553118e-03,  9.27776490e-03,  9.16813326e-03,\n",
       "        9.14418106e-03,  9.10288490e-03,  9.03646433e-03,  8.96532840e-03,\n",
       "        8.92652439e-03,  8.85824192e-03,  8.80110198e-03,  8.77634932e-03,\n",
       "        8.65789124e-03,  8.61972068e-03,  8.48313933e-03,  8.53582444e-03,\n",
       "        8.57629462e-03,  8.42791280e-03,  8.37460824e-03,  8.29651753e-03,\n",
       "        8.26414047e-03,  8.16709307e-03,  8.01638541e-03,  8.10971986e-03,\n",
       "        8.07064703e-03,  7.90944942e-03,  7.89122034e-03,  7.81552191e-03,\n",
       "        7.78624303e-03,  7.70469980e-03,  7.62692828e-03,  7.52519971e-03,\n",
       "        7.55213340e-03,  7.47384551e-03,  7.49074316e-03,  7.40757855e-03,\n",
       "        7.28870554e-03,  7.27471268e-03,  7.21508080e-03,  7.15992706e-03,\n",
       "        7.04509011e-03,  7.09211939e-03,  7.16942654e-03,  6.97789533e-03,\n",
       "        6.89137237e-03,  6.86436281e-03,  6.81022609e-03,  6.72337776e-03,\n",
       "        6.66132284e-03,  6.63608750e-03,  6.75480283e-03,  6.70767779e-03,\n",
       "        6.57654190e-03,  6.51493565e-03,  6.40974367e-03,  6.46534355e-03,\n",
       "        6.38126294e-03,  6.32539400e-03,  6.27168280e-03,  6.29664221e-03,\n",
       "        6.21491630e-03,  6.17209384e-03,  6.14230087e-03,  6.12142810e-03,\n",
       "        5.92673807e-03,  6.02219383e-03,  6.03872818e-03,  5.86709381e-03,\n",
       "        5.74579771e-03,  5.80295098e-03,  5.82256253e-03,  5.82832719e-03,\n",
       "        5.71143276e-03,  5.64190327e-03,  5.67308162e-03,  5.59975384e-03,\n",
       "        5.53884795e-03,  5.45294336e-03,  5.58520337e-03,  5.38046055e-03,\n",
       "        5.31718516e-03,  5.39123697e-03,  3.60115997e-03,  5.28654834e-03,\n",
       "        5.23952877e-03,  3.65100727e-03,  3.67244737e-03,  5.25138298e-03,\n",
       "        5.17372889e-03,  5.10551314e-03,  5.14579304e-03,  5.03661228e-03,\n",
       "        3.73329981e-03,  3.76549514e-03,  3.79978326e-03,  4.98496300e-03,\n",
       "        4.87678089e-03,  4.94559693e-03,  4.94161714e-03,  3.83391293e-03,\n",
       "        3.83926992e-03,  4.81897816e-03,  4.82903197e-03,  4.78087944e-03,\n",
       "        3.87899940e-03,  3.89358534e-03,  3.93386168e-03,  4.74929407e-03,\n",
       "        3.99683080e-03,  4.03829081e-03,  4.65366248e-03,  4.60444417e-03,\n",
       "        4.70082952e-03,  4.08231563e-03,  4.71214007e-03,  4.11584479e-03,\n",
       "        4.55075224e-03,  4.14563432e-03,  4.49002027e-03,  4.51204083e-03,\n",
       "        4.26569251e-03,  4.19004011e-03,  4.31885947e-03,  4.39274460e-03,\n",
       "        4.37508942e-03,  4.34981948e-03,  4.19743823e-03,  4.46072151e-03,\n",
       "        4.27556387e-03,  3.09658791e-03,  3.13023433e-03,  3.15977361e-03,\n",
       "        3.23139143e-03,  3.43997707e-03,  3.53572575e-03,  3.49227210e-03,\n",
       "        3.58211391e-03,  3.38513516e-03,  3.27073398e-03,  3.35918884e-03,\n",
       "        3.34564826e-03,  3.18037570e-03,  3.09082921e-03,  3.02574065e-03,\n",
       "        2.99089844e-03,  2.97236094e-03,  2.93243032e-03,  2.89472065e-03,\n",
       "        2.87213882e-03,  2.88615411e-03,  2.81188097e-03,  2.73394848e-03,\n",
       "        2.75219979e-03,  2.12416081e-03,  2.65638636e-03,  2.62340036e-03,\n",
       "        2.48909712e-03,  2.58712272e-03,  2.40438567e-03,  2.30483308e-03,\n",
       "        2.18216927e-03,  2.56779547e-03,  2.46022774e-03,  2.52779472e-03,\n",
       "        2.26334081e-03,  2.36789051e-03,  2.78158717e-03,  2.44872930e-03,\n",
       "        2.77062491e-03,  2.20313834e-03,  2.23482022e-03,  2.22367525e-03,\n",
       "        2.68980657e-03,  2.24659865e-03,  2.15365227e-03,  2.03462674e-03,\n",
       "        1.92925025e-03,  2.01106624e-03,  2.01687153e-03,  1.99745997e-03,\n",
       "        1.96793239e-03,  1.95477347e-03,  1.88573609e-03,  1.83855250e-03,\n",
       "        1.86428040e-03,  1.76118050e-03,  1.82170999e-03,  1.81290521e-03,\n",
       "        1.85875211e-03,  1.73991192e-03,  1.69769422e-03,  1.68403158e-03,\n",
       "        1.66829063e-03,  1.63519187e-03,  1.57683290e-03,  1.59000395e-03,\n",
       "        1.60335450e-03,  1.50366141e-03,  1.54027418e-03,  1.52201087e-03,\n",
       "        1.47975652e-03,  9.17955755e-04,  1.47144321e-03,  1.45087593e-03,\n",
       "        1.42071704e-03,  9.27365633e-04,  9.72765864e-04,  9.46816707e-04,\n",
       "        9.58905544e-04,  9.54470305e-04,  9.99663562e-04,  1.35888616e-03,\n",
       "        1.33354717e-03,  1.32674065e-03,  1.02892924e-03,  1.03472109e-03,\n",
       "        1.04737356e-03,  1.05924981e-03,  1.07440172e-03,  1.09966566e-03,\n",
       "        1.30909269e-03,  1.12282232e-03,  1.22414188e-03,  1.18730352e-03,\n",
       "        1.25096531e-03,  1.11079643e-03,  1.23122085e-03,  1.13004213e-03,\n",
       "        1.16621541e-03,  1.17922685e-03,  1.30167435e-03,  1.27855159e-03,\n",
       "        1.28198436e-03,  1.28421681e-03,  7.47499366e-04,  7.56863207e-04,\n",
       "        8.19313519e-04,  8.62509493e-04,  8.49328531e-04,  8.52741237e-04,\n",
       "        7.68653387e-04,  8.38549736e-04,  7.89808588e-04,  8.01747244e-04,\n",
       "        7.78153878e-04,  7.99696040e-04,  7.36166815e-04,  7.27075610e-04,\n",
       "        7.21004328e-04,  7.03001713e-04,  6.90917423e-04,  6.61643349e-04,\n",
       "        6.52818226e-04,  6.42480153e-04,  6.32792454e-04,  6.28100465e-04,\n",
       "        6.20932904e-04,  6.18514223e-04,  5.39493151e-04,  5.28414744e-04,\n",
       "        5.04843499e-04,  5.57316763e-04,  5.76664786e-04,  5.92974746e-04,\n",
       "        5.99958239e-04,  4.53036511e-04,  4.94172729e-04,  5.80122634e-04,\n",
       "        5.55646995e-04,  4.88260181e-04,  4.86251850e-04,  5.96691170e-04,\n",
       "        4.64504712e-04,  4.67766069e-04,  4.20220935e-04,  4.30253233e-04,\n",
       "        4.14804857e-04,  4.07778972e-04,  4.03030994e-04,  3.99532385e-04,\n",
       "        3.97128673e-04,  3.83275680e-04,  3.88516686e-04,  3.76919827e-04,\n",
       "        3.62813202e-04,  3.67058035e-04,  3.54073656e-04,  3.41142670e-04,\n",
       "        3.50933982e-04,  3.44722646e-04,  3.23732019e-04,  3.12527051e-04,\n",
       "        3.01973736e-04,  2.99337875e-04,  2.82050936e-04,  2.92891445e-04,\n",
       "        2.77904052e-04,  2.73254830e-04,  2.63394110e-04,  2.60080650e-04,\n",
       "        2.20652586e-04,  2.65697675e-04,  2.58403186e-04,  2.40144693e-04,\n",
       "        2.43767106e-04,  2.53645554e-04,  2.47601673e-04,  2.00345508e-04,\n",
       "        2.21358395e-04,  1.99349027e-04,  2.11574791e-04,  2.08010751e-04,\n",
       "        2.10985677e-04,  9.49261716e-05,  9.72507939e-05,  9.76588542e-05,\n",
       "        9.83371367e-05,  9.90798442e-05,  1.74637606e-04,  1.38587717e-04,\n",
       "        1.34447703e-04,  1.07654234e-04,  1.10831956e-04,  1.24522991e-04,\n",
       "        1.47831317e-04,  1.22085202e-04,  1.16402541e-04,  1.70720020e-04,\n",
       "        1.69386624e-04,  1.67414945e-04,  1.64482678e-04,  1.18356373e-04,\n",
       "        1.55854310e-04,  1.62509898e-04,  1.19316821e-04,  1.13183474e-04,\n",
       "        1.54201356e-04,  1.56633050e-04,  1.59539031e-04,  1.58817925e-04,\n",
       "        1.13421580e-04,  9.24986883e-05,  7.92719649e-05,  7.70356073e-05,\n",
       "        8.46465576e-05,  8.53335594e-05,  7.32019528e-05,  6.95035268e-05,\n",
       "        6.57407200e-05,  6.77341403e-05,  7.45176712e-05,  6.87144878e-05,\n",
       "        5.90110143e-05,  5.68599474e-05,  5.52540880e-05,  5.46107652e-05,\n",
       "        5.49183956e-05,  5.17359488e-05,  5.09545931e-05,  4.92719825e-05,\n",
       "        4.79692584e-05,  4.82835217e-05,  4.61555739e-05,  4.74037076e-05,\n",
       "        4.39283735e-05,  4.09222334e-05,  3.92789618e-05,  3.80596743e-05,\n",
       "        3.51488807e-05,  3.47848603e-05,  2.02408309e-05,  3.35815014e-05,\n",
       "        2.14317201e-05,  2.95774108e-05,  3.29832555e-05,  3.29736199e-05,\n",
       "        2.75359947e-05,  2.51756402e-05,  2.48689969e-05,  2.27921158e-05,\n",
       "        3.11571006e-05,  2.21679188e-05,  3.07332021e-05,  2.78506298e-05,\n",
       "        2.98894331e-05,  2.45774628e-05,  1.90936362e-05,  1.88053259e-05,\n",
       "        1.64671757e-05,  1.56506751e-05,  1.46796895e-05,  1.43773421e-05,\n",
       "        1.35761302e-05,  1.34740830e-05,  1.24278011e-05,  1.21238430e-05,\n",
       "        1.18819021e-05,  1.27221352e-05,  1.13358339e-05,  9.02818979e-06,\n",
       "        1.03431517e-05,  9.31879666e-06,  1.06789062e-05,  1.06211054e-05,\n",
       "        5.64429445e-06,  7.96126820e-06,  7.89403356e-06,  6.75175570e-06,\n",
       "        7.20242488e-06,  7.13405847e-06,  4.98205264e-06,  4.63140134e-06,\n",
       "        4.39022584e-06,  4.30670647e-06,  3.38556114e-06,  3.61113222e-06,\n",
       "        3.54512583e-06,  2.42198513e-06,  3.14187782e-06,  2.92115220e-06,\n",
       "        2.45764990e-06,  2.14342788e-06,  2.07520782e-06,  1.90053527e-06,\n",
       "        1.88198911e-06,  1.70843392e-06,  1.52415657e-06,  1.58432450e-06,\n",
       "        1.62797221e-06,  1.26674301e-06,  8.54409983e-07,  8.76826740e-07,\n",
       "        9.93705509e-07,  9.34608638e-07,  5.87901568e-07,  5.43435900e-07,\n",
       "        4.55800354e-07,  5.32448391e-07,  4.19593002e-07,  3.63030501e-07,\n",
       "        3.64672029e-07,  1.59250500e-07,  1.94992116e-07,  2.86416147e-07,\n",
       "        2.61829607e-07,  1.02292380e-07,  4.57336002e-08,  1.24548828e-08,\n",
       "        1.33663582e-08,  3.73399225e-08,  3.65001077e-08,  8.07021516e-10,\n",
       "       -5.36934777e-18,  5.01967455e-18,  1.88344852e-19,  5.66907352e-21,\n",
       "        1.03863427e-20,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = np.cov(std_x.T)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(S)\n",
    "eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. You may notice that the results contain the complex numbers of which the imaginary part is zero. Please remove the imaginary part with np.real()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues = np.real(eigenvalues)\n",
    "eigenvectors = np.real(eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Use the top-30 eigenvectors (with the largest three eigenvalues) to transform the training data to Z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 784)\n",
      "(784, 30)\n",
      "(60000, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-3.45384876, -1.29392457,  0.77492676, ..., -0.6360691 ,\n",
       "        -0.51386024,  0.5206804 ],\n",
       "       [-6.93536165, -1.22405311,  3.20964681, ..., -0.16166522,\n",
       "        -1.43901047,  0.3729488 ],\n",
       "       [-2.76450681,  1.47018294,  0.13180638, ..., -0.52084165,\n",
       "         0.02981159,  1.12786725],\n",
       "       ...,\n",
       "       [-2.26958978,  0.5600067 , -0.13918709, ...,  0.64755595,\n",
       "        -0.71228873,  1.51175629],\n",
       "       [-3.48001928, -0.08968016,  2.88619235, ...,  1.11891731,\n",
       "        -0.48737813, -0.14931916],\n",
       "       [-2.28769762, -0.16468747,  3.05152655, ...,  0.7286741 ,\n",
       "        -0.21899266, -0.11495676]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.argsort(eigenvalues)[::-1]\n",
    "eigenvalues,eigenvectors = eigenvalues[index], eigenvectors[:, index]\n",
    "print(eigenvectors.shape)\n",
    "eigenvectors = eigenvectors[:,0:30]\n",
    "\n",
    "print(eigenvectors.shape)\n",
    "print(std_x.shape)\n",
    "Z = np.dot(std_x,eigenvectors)\n",
    "Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Reconstruct the training data from Z to $\\widetilde{X}$, then multiply it by 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_remake = np.dot(Z,eigenvectors.T) * 255.0\n",
    "x_remake.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Plot the first sample of the reconstructed data $\\widetilde{X}$. Compare it with the original one. Are they close to each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e586754d90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "firstsample_data = x_remake[0]\n",
    "data_reshape2 = firstsample_data.reshape(28,28)\n",
    "plt.imshow(data_reshape2, vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Calculate the mean square error of the above reconstructed with respect to the original one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1525.2600011382613\n"
     ]
    }
   ],
   "source": [
    "mse = ((x_remake - data_x)**2).mean(axis=1)\n",
    "print(mse[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Now try another experiment. Pick up the top-100 eigenvectors (with the largest 100 eigenvalues) to transform the training data. Then again plot the first reconstructed sample and calculate the mean square error. You may warp it with a python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE for the first sample is 540.2871121074667\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pca100_show(data_x):\n",
    "    std_x = data_x/255.0\n",
    "    S = np.cov(std_x.T)\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(S)\n",
    "    index = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues,eigenvectors = eigenvalues[index], eigenvectors[:, index]\n",
    "    eigenvectors = eigenvectors[:,:100]\n",
    "    eigenvalues = np.real(eigenvalues)\n",
    "    eigenvectors = np.real(eigenvectors)\n",
    "    Z = np.dot(std_x,eigenvectors)\n",
    "\n",
    "    x_remake = np.dot(Z,eigenvectors.T) * 255.0\n",
    "    firstsample_data = x_remake[0]\n",
    "    data_reshape = firstsample_data.reshape(28,28)\n",
    "    plt.imshow(data_reshape, vmin=0, vmax=255)\n",
    "    mse = ((x_remake - data_x)**2).mean(axis=1)\n",
    "    print(\"The MSE for the first sample is\",mse[0])\n",
    "\n",
    "pca100_show(data_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Classification is among the most important areas of machine learning, and logistic regression is one of its basic methods. Basically, it takes the sample features as input and predicts its categorical label. Take MNIST as example, we can take the pixel values of a sample image as input and predict its number. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we first show how to apply logistic regression to the original data (assume that X has been standardized)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Import the scikit-learn library and use the LogisticRegression module to fix the data. It may run about one minute for the MNIST training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=1000, random_state=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# TO DO: please indicate your standardized training feature data 'X' \n",
    "#                        and the training label data 'y' from \"mnist_train.csv\"\n",
    "X = std_x.values\n",
    "y = train_data['label']\n",
    "\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000).fit(X, y) \n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Load the testing data \"mnist_test.csv\", remember to stardardize it by dividing 255.0. Use the above fitted model \"clf\" to predict the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: please indicate your testing feature data 'test_X' from \"mnist_test.csv\", remember to do standardization.\n",
    "test_data = pd.read_csv('./mnist_test.csv')\n",
    "test_dataX = test_data.iloc[:,1:]\n",
    "print(test_dataX.shape)\n",
    "test_X = test_dataX/255.0\n",
    "predict_y = clf.predict(test_X)\n",
    "predict_y = predict_y.reshape(10000,1)\n",
    "predict_y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Calculate the accuracy of the fitted model on the testing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model obtains 92.560000% of accuracy.\n"
     ]
    }
   ],
   "source": [
    "# TO DO: please indicate your testing label data 'test_y'\n",
    "test_y = test_data.iloc[:,0:1]\n",
    "\n",
    "true_count = np.sum(predict_y ==test_y )\n",
    "true_count\n",
    "print(\"The model obtains %f%% of accuracy.\" % (true_count / len(test_y) * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are expected to get around 92% of accuracy on the testing dataset. \n",
    "\n",
    "Now we would like you to find if we can use the transformed features of PCA to do the same logistic regression task. It has two advantages. First, it decreases the storage requirement of the data. Second, by dimension reduction, the running time of logistic regression can be shorten. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. Use the top-100 eigenvectors to transform the standardized training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pca_change(data_x,k):\n",
    "    std = data_x/255.0\n",
    "    S = np.cov(std.T)\n",
    "    evalues, evectors = np.linalg.eig(S)\n",
    "    evalues = np.real(evalues)\n",
    "    evectors = np.real(evectors)\n",
    "    index = np.argsort(evalues)[::-1]\n",
    "    evalues,evectors = evalues[index], evectors[:, index]\n",
    "    evectors = evectors[:,0:k]\n",
    "\n",
    "    Z = np.dot(std,evectors)\n",
    "    res = np.dot(Z,evectors.T)\n",
    "    return res\n",
    "\n",
    "Z = pca_change(data_x,100)\n",
    "Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Use the transformed data to do logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Z\n",
    "y = train_data['label']\n",
    "\n",
    "clf_test = LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000).fit(X, y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. Apply the new model to the testing dataset. Notice that you should do the same standardization and PCA transformation for the testing dataset. Again you can calculate the model accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model obtains 92.200000% of accuracy.\n"
     ]
    }
   ],
   "source": [
    "test_Z = pca_change(test_dataX,100)\n",
    "test_Z\n",
    "predict_pcay = clf_test.predict(test_Z).reshape(10000,1)\n",
    "\n",
    "true_count = np.sum(predict_pcay == test_y)\n",
    "print(\"The model obtains %f%% of accuracy.\" % (true_count / len(test_y) * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17. Suppose that we expect that the fitted model has at least 90% of accuracy on the testing dataset. Please find that how many eigenvectors should we choose at least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model obtains 90.130000% of accuracy.\n",
      "The eigenvectors should be 34\n"
     ]
    }
   ],
   "source": [
    "def accuracy(k):\n",
    "    X = pca_change(data_x,k)\n",
    "    y = train_data['label']\n",
    "\n",
    "    clf_test = LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000).fit(X, y) \n",
    "    test_Z = pca_change(test_dataX,k)\n",
    "    predict_pcay = clf_test.predict(test_Z).reshape(10000,1)\n",
    "    true_count = np.sum(predict_pcay == test_y)\n",
    "    print(\"The model obtains %f%% of accuracy.\" % (true_count / len(test_y) * 100.0))\n",
    "    print(\"The eigenvectors should be\",k)\n",
    "    \n",
    "accuracy(34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] THE MNIST DATABASE of handwritten digits. http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "[2] Logistic Regression. https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
